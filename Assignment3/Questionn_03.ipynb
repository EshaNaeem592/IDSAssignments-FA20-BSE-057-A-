{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 25-nov-2023\n",
        "# CSC461 – Assignment3 – Machine Learning\n",
        "# Esha Naeem\n",
        "# FA20-BSE-057(A)\n",
        "# A brief description of the task:The task involves employing the Random Forest classification algorithm for gender prediction, utilizing two distinct cross-validation strategies: Monte Carlo and Leave P-Out. In the Monte Carlo approach, the dataset is randomly divided into training and test sets across multiple iterations, and the F1 score is averaged over these iterations. On the other hand, the Leave P-Out strategy involves systematically using P instances as the test set while training the model on the remaining data, repeating this process for all possible test sets. The aim is to evaluate the Random Forest model's performance under both cross-validation techniques and report F1 scores, which strike a balance between precision and recall.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, LeavePOut\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "umS-FJZpeeaP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/MyDrive/Datasets/gender-prediction (1).csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAdH9r1QenWe",
        "outputId": "b7b913ad-9935-4ed2-e2a0-33e66da0fa88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['beard', 'hair_length', 'scarf', 'eye_color'], drop_first=True)\n",
        "\n",
        "X = df_encoded.drop(columns=['gender'])\n",
        "y = df_encoded['gender']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Monte Carlo cross-validation with error debugging\n",
        "# Monte Carlo cross-validation parameters\n",
        "n_splits = 5\n",
        "test_size = 0.2\n",
        "random_state = 42\n",
        "\n",
        "# Monte Carlo cross-validation with error debugging\n",
        "monte_carlo_cv = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
        "try:\n",
        "    monte_carlo_f1_scores = cross_val_score(rf_classifier, X, y, cv=monte_carlo_cv, scoring='f1_macro', error_score='raise')\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "    raise e\n",
        "\n",
        "# Print the Monte Carlo Cross-Validation parameters\n",
        "print(f\"Monte Carlo Cross-Validation Parameters: n_splits={n_splits}, test_size={test_size}, random_state={random_state}\")\n",
        "\n",
        "# Print the F1 scores for each iteration of Monte Carlo Cross-Validation\n",
        "print(\"\\nMonte Carlo Cross-Validation F1 Scores:\")\n",
        "for i, score in enumerate(monte_carlo_f1_scores, 1):\n",
        "    print(f\"Iteration {i}: {score}\")\n",
        "\n",
        "# Leave P-Out cross-validation (e.g., P=2)\n",
        "leave_p_out = LeavePOut(p=1)\n",
        "leave_p_out_f1_scores = cross_val_score(rf_classifier, X, y, cv=leave_p_out, scoring='f1_macro')\n",
        "\n",
        "# Report F1 scores for Leave P-Out Cross-Validation\n",
        "print(\"\\nLeave P-Out Cross-Validation F1 Scores:\", leave_p_out_f1_scores)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ5F63qEfBxb",
        "outputId": "137874cc-0a96-4977-cd02-28fb03efc16d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo Cross-Validation Parameters: n_splits=5, test_size=0.2, random_state=42\n",
            "\n",
            "Monte Carlo Cross-Validation F1 Scores:\n",
            "Iteration 1: 1.0\n",
            "Iteration 2: 0.8633540372670807\n",
            "Iteration 3: 0.9494252873563218\n",
            "Iteration 4: 0.9544513457556936\n",
            "Iteration 5: 0.9494252873563218\n",
            "\n",
            "Leave P-Out Cross-Validation F1 Scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    }
  ]
}