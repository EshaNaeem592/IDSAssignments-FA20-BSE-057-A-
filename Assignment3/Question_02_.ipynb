{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tt67nGmkYrSW"
      },
      "outputs": [],
      "source": [
        "# 25-nov-2023\n",
        "# CSC461 – Assignment3 – Machine Learning\n",
        "# Esha Naeem\n",
        "# FA20-BSE-057(A)\n",
        "# A brief description of the task:Applyied three classification algorithms (Logistic Regression, Support Vector Machines, and Multilayer Perceptron) on a gender prediction dataset.Split the dataset into a training set (2/3 of the data) and a test set (1/3 of the data) using a train/test split ratio then Model Training and Evaluation Apply Logistic Regression, Support Vector Machines, and Multilayer Perceptron classification algorithms on the training set and evaluate their performance on the test set.Part1:-Calculated the number of instances that are incorrectly classified by each algorithm.Part2:-Train/Test Split Ratio Change: Repeat the experiment with a different train/test split ratio (80/20) and observe if there are any changes in the results.Part3:-Attribute Importance: Identified two attributes that  are the most \"powerful\" in the prediction task. Explain why you consider these attributes to be influential. Part4:-Attribute Exclusion: Exclude the two identified attributes from the dataset and rerun the experiment with the 80/20 train/test split ratio. Display any changes in the classification results and I provide explanations for  observed differences.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db_MnV_Nc4mI",
        "outputId": "1b5075b0-6480-4fa5-9c9a-e979e5a6bba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Datasets/gender-prediction (1).csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "lN_egVbJc6lR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables to numeric values\n",
        "le = LabelEncoder()\n",
        "df['beard'] = le.fit_transform(df['beard'])\n",
        "df['hair_length'] = le.fit_transform(df['hair_length'])\n",
        "df['scarf'] = le.fit_transform(df['scarf'])\n",
        "df['eye_color'] = le.fit_transform(df['eye_color'])\n",
        "df['gender'] = le.fit_transform(df['gender'])\n"
      ],
      "metadata": {
        "id": "b9p5FXvNdrRK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('gender', axis=1)\n",
        "y = df['gender']"
      ],
      "metadata": {
        "id": "19-Gie9_d8oY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "drkMMobWeBPQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_predictions = logreg.predict(X_test)\n",
        "\n",
        "# SVM\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predictions = svm.predict(X_test)\n",
        "\n",
        "# Multilayer Perceptron\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "mlp_predictions = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the models\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_predictions))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
        "print(\"MLP Accuracy:\", accuracy_score(y_test, mlp_predictions))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46xM3_xteJr9",
        "outputId": "f85ac36c-97f1-4617-9266-5b64a050e9a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8648648648648649\n",
            "SVM Accuracy: 0.7567567567567568\n",
            "MLP Accuracy: 0.8108108108108109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Part1\")\n",
        "incorrectly_classified_logreg = (1 - accuracy_score(y_test, logreg_predictions)) * len(y_test)\n",
        "\n",
        "incorrectly_classified_svm = (1 - accuracy_score(y_test, svm_predictions)) * len(y_test)\n",
        "incorrectly_classified_mlp = (1 - accuracy_score(y_test, mlp_predictions)) * len(y_test)\n",
        "\n",
        "print(\"Number of incorrectly classified instances (Logistic Regression):\", int(incorrectly_classified_logreg))\n",
        "print(\"Number of incorrectly classified instances (SVM):\", int(incorrectly_classified_svm))\n",
        "print(\"Number of incorrectly classified instances (MLP):\", int(incorrectly_classified_mlp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a2p5Lt8zsVs",
        "outputId": "f5cc2944-4037-4e43-c3c5-d0b8bbcfe800"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part1\n",
            "Number of incorrectly classified instances (Logistic Regression): 4\n",
            "Number of incorrectly classified instances (SVM): 8\n",
            "Number of incorrectly classified instances (MLP): 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PART2:Changes happen that you shown in result:\")\n",
        "# Split the dataset into training and testing sets (80/20 train, test)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_predictions = logreg.predict(X_test)\n",
        "\n",
        "# SVM\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predictions = svm.predict(X_test)\n",
        "\n",
        "# Multilayer Perceptron\n",
        "mlp.fit(X_train, y_train)\n",
        "mlp_predictions = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the models\n",
        "print(\"\\nLogistic Regression Accuracy (80/20 split):\", accuracy_score(y_test, logreg_predictions))\n",
        "print(\"SVM Accuracy (80/20 split):\", accuracy_score(y_test, svm_predictions))\n",
        "print(\"MLP Accuracy (80/20 split):\", accuracy_score(y_test, mlp_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR55ghLT1nv-",
        "outputId": "96118a1a-b74c-497e-9e1a-bc4f762dd672"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART2:Changes happen that you shown in result:\n",
            "\n",
            "Logistic Regression Accuracy (80/20 split): 1.0\n",
            "SVM Accuracy (80/20 split): 0.8181818181818182\n",
            "MLP Accuracy (80/20 split): 0.7727272727272727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PART3\")\n",
        "print(\"Beard:Explanation: The presence or absence of a beard is often strongly associated with gender, as beards are more commonly associated with males. This attribute can serve as a significant indicator for the model in predicting gender.\")\n",
        "print(\"Height:Explanation: While there is overlap in the height distribution between genders, on average, males tend to be taller than females. Therefore, height can be a useful feature for predicting gender. However, it's important to note that relying solely on height for gender prediction might lead to misclassifications due to the natural variation in height within each gender.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8c79jna15ck",
        "outputId": "14cef590-1410-42f4-cb3c-14f0aaa46ca4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART3\n",
            "Beard:Explanation: The presence or absence of a beard is often strongly associated with gender, as beards are more commonly associated with males. This attribute can serve as a significant indicator for the model in predicting gender.\n",
            "Height:Explanation: While there is overlap in the height distribution between genders, on average, males tend to be taller than females. Therefore, height can be a useful feature for predicting gender. However, it's important to note that relying solely on height for gender prediction might lead to misclassifications due to the natural variation in height within each gender.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PART4->(Difference in orignal and After Exclude2Attributes)\")\n",
        "# Original Features\n",
        "X_original = df.drop(['gender'], axis=1)\n",
        "y_original = df['gender']\n",
        "\n",
        "# Split the dataset into training and testing sets (80/20 train/test split)\n",
        "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(X_original, y_original, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg_original = LogisticRegression()\n",
        "logreg_original.fit(X_train_original, y_train_original)\n",
        "logreg_predictions_original = logreg_original.predict(X_test_original)\n",
        "\n",
        "# SVM\n",
        "svm_original = SVC()\n",
        "svm_original.fit(X_train_original, y_train_original)\n",
        "svm_predictions_original = svm_original.predict(X_test_original)\n",
        "\n",
        "# Multilayer Perceptron\n",
        "mlp_original = MLPClassifier()\n",
        "mlp_original.fit(X_train_original, y_train_original)\n",
        "mlp_predictions_original = mlp_original.predict(X_test_original)\n",
        "\n",
        "# Print original results\n",
        "print(\"Original Logistic Regression Accuracy:\", accuracy_score(y_test_original, logreg_predictions_original))\n",
        "print(\"Original SVM Accuracy:\", accuracy_score(y_test_original, svm_predictions_original))\n",
        "print(\"Original MLP Accuracy:\", accuracy_score(y_test_original, mlp_predictions_original))\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"AFTER Exclude 2Attributes\")\n",
        "# Exclude 'beard' and 'height' from the features\n",
        "X = df.drop(['gender', 'beard', 'height'], axis=1)\n",
        "y = df['gender']\n",
        "\n",
        "# Encode categorical variables to numeric values\n",
        "le = LabelEncoder()\n",
        "X['hair_length'] = le.fit_transform(X['hair_length'])\n",
        "X['scarf'] = le.fit_transform(X['scarf'])\n",
        "X['eye_color'] = le.fit_transform(X['eye_color'])\n",
        "\n",
        "# Split the dataset into training and testing sets (80/20 train/test split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_predictions = logreg.predict(X_test)\n",
        "\n",
        "# SVM\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predictions = svm.predict(X_test)\n",
        "\n",
        "# Multilayer Perceptron\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "mlp_predictions = mlp.predict(X_test)\n",
        "\n",
        "# Print new results\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_predictions))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
        "print(\"MLP Accuracy:\", accuracy_score(y_test, mlp_predictions))\n",
        "\n",
        "print(\"Conclusion:After excluding the 'beard' and 'height' attributes from the gender prediction models, we observed notable changes in the feature set and model performance. The original models, which included all attributes, demonstrated certain levels of accuracy and classification performance. However, in the modified models that excluded 'beard' and 'height,' we assessed the impact on performance metrics. If the models exhibited similar or improved performance, it suggested that these attributes might not have been crucial for accurately predicting gender. Conversely, a significant drop in performance indicated the importance of 'beard' and 'height' in contributing valuable information to the models. \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hmfKU9X52B_",
        "outputId": "7a496269-c33a-4caa-9484-08ecb09c2e83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART4->(Difference in orignal and After Exclude2Attributes)\n",
            "Original Logistic Regression Accuracy: 1.0\n",
            "Original SVM Accuracy: 0.8181818181818182\n",
            "Original MLP Accuracy: 0.7727272727272727\n",
            "\n",
            "\n",
            "\n",
            "AFTER Exclude 2Attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9545454545454546\n",
            "SVM Accuracy: 0.8181818181818182\n",
            "MLP Accuracy: 0.45454545454545453\n",
            "Conclusion:After excluding the 'beard' and 'height' attributes from the gender prediction models, we observed notable changes in the feature set and model performance. The original models, which included all attributes, demonstrated certain levels of accuracy and classification performance. However, in the modified models that excluded 'beard' and 'height,' we assessed the impact on performance metrics. If the models exhibited similar or improved performance, it suggested that these attributes might not have been crucial for accurately predicting gender. Conversely, a significant drop in performance indicated the importance of 'beard' and 'height' in contributing valuable information to the models. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "cgFI-rM78sYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "Nskn3PFfa3Wn"
      }
    }
  ]
}